{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a088959-6313-491b-bb0c-e0edea5094fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddbee37-c526-45ca-aaa9-458c979b2c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:02:46.837321Z",
     "iopub.status.busy": "2022-09-06T17:02:46.837163Z",
     "iopub.status.idle": "2022-09-06T17:02:47.513355Z",
     "shell.execute_reply": "2022-09-06T17:02:47.512941Z",
     "shell.execute_reply.started": "2022-09-06T17:02:46.837289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer # (sent_tokenize)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "SKLEARN_WORD_TOKENIZER_REGEX = r'(?u)\\b\\w\\w+\\b'  # SKLEARN's default selects 2+ tokens\n",
    "CUSTOM_WORD_TOKENIZER_REGEX = r'(?u)\\b\\w+\\b'  # select 1+ tokens\n",
    "\n",
    "# End of sentence pattern matches an optional not-word symbol, any spacing symbols, optional \\r, one more \\n, any spacing symbols and any non-word symbols\n",
    "eos_pattern = re.compile(r'(?u)\\W?\\s*\\r?\\n+\\s*' + r'\\W*')\n",
    "# End of sentence punctuation pattern matches one ore more \".\" or \"!\" or \"?\" ate the end of the string\n",
    "eosp_pattern = re.compile(r'(?u)\\.+$|!+$|\\?+$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c7f59-1137-47db-8ab5-460f85ab2a22",
   "metadata": {},
   "source": [
    "# custom_sentence_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a61c74ff-3c96-4d38-93cd-5469e1b79a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:15:47.495818Z",
     "iopub.status.busy": "2022-09-06T17:15:47.495678Z",
     "iopub.status.idle": "2022-09-06T17:15:47.498580Z",
     "shell.execute_reply": "2022-09-06T17:15:47.498097Z",
     "shell.execute_reply.started": "2022-09-06T17:15:47.495806Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_sentence_tokenizer(document):\n",
    "    # WARNING: This custom sentence tokenizer destroys the original word capitalizing (to lower case) and removes the\n",
    "    # document's final period because of the sucessive sentence breakdown tricks\n",
    "    # TODO: is it possible to preserve the case of acronyms?  I still don't think so...\n",
    "\n",
    "    # Let PunktSentenceTokenizer breakdown sentences after replacing new lines with periods\n",
    "    sentences = PunktSentenceTokenizer().tokenize(eos_pattern.sub('. ', document))\n",
    "    # Removing final periods to avoid same sentences with or without final periods\n",
    "    sentences = [eosp_pattern.sub('', sentence) for sentence in sentences]\n",
    "\n",
    "    # Let PunktSentenceTokenizer breakdown sentences AGAIN by capitalizing words in the previous sentence tokens\n",
    "    # sentences = [PunktSentenceTokenizer().tokenize(' '.join(word.capitalize() for word in sentence.split())) for sentence in sentences]\n",
    "    # Lower case sentence to avoid non-original capitalized words but destroying the original word capitalizing.\n",
    "    # sentences = [sentence.lower() for sub_sentence in sentences for sentence in sub_sentence]\n",
    "    # Removing final periods AGAIN to avoid same sentences with or without final periods\n",
    "    # sentences = [eosp_pattern.sub('', sentence) for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768276ee-b90d-46cb-b4fc-b919d5c4fb1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faea6870-a6e7-49ea-9242-775b11899e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:15:48.616395Z",
     "iopub.status.busy": "2022-09-06T17:15:48.616257Z",
     "iopub.status.idle": "2022-09-06T17:15:48.621034Z",
     "shell.execute_reply": "2022-09-06T17:15:48.620722Z",
     "shell.execute_reply.started": "2022-09-06T17:15:48.616384Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. 4\\n. 3 4.\\n 2 3 4\\n 1 2 3 4...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['\\n. ', '.\\n ', '\\n ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Mr. 4. 3 4. 2 3 4. 1 2 3 4...'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = 'one\\n. one two.\\n one two three\\n one two three four.'\n",
    "document = 'Mr. 4\\n. 3 4.\\n 2 3 4\\n 1 2 3 4...'\n",
    "# End of sentence pattern matches an optional not-word symbol, any spacing symbols, optional \\r, one more \\n, any spacing symbols and any non-word symbols\n",
    "eos_pattern = re.compile(r'(?u)\\W?\\s*\\r?\\n+\\s*' + r'\\W*')\n",
    "display(document)\n",
    "display(eos_pattern.findall(document))\n",
    "eos_pattern.sub('. ', document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "964a354c-e5ca-416a-a499-299121b640c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:15:49.398377Z",
     "iopub.status.busy": "2022-09-06T17:15:49.398235Z",
     "iopub.status.idle": "2022-09-06T17:15:49.401425Z",
     "shell.execute_reply": "2022-09-06T17:15:49.401093Z",
     "shell.execute_reply.started": "2022-09-06T17:15:49.398366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.', '4.', '3 4.', '2 3 4.', '1 2 3 4...']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = PunktSentenceTokenizer().tokenize(eos_pattern.sub('. ', document)); sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be4ed2b1-00c5-461d-9333-c0e550c1df1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:15:50.360807Z",
     "iopub.status.busy": "2022-09-06T17:15:50.360668Z",
     "iopub.status.idle": "2022-09-06T17:15:50.363546Z",
     "shell.execute_reply": "2022-09-06T17:15:50.363147Z",
     "shell.execute_reply.started": "2022-09-06T17:15:50.360795Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', '4', '3 4', '2 3 4', '1 2 3 4']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [eosp_pattern.sub('', sentence) for sentence in sentences]; sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a0f0fcf-d1ab-45fa-8958-d222c3365fce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:16:04.153317Z",
     "iopub.status.busy": "2022-09-06T17:16:04.153176Z",
     "iopub.status.idle": "2022-09-06T17:16:04.155146Z",
     "shell.execute_reply": "2022-09-06T17:16:04.154847Z",
     "shell.execute_reply.started": "2022-09-06T17:16:04.153306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sentences = [PunktSentenceTokenizer().tokenize(' '.join(word.capitalize() for word in sentence.split())) for sentence in sentences]; sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8dc05604-e921-4112-8dc6-9a8727966bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:16:04.589865Z",
     "iopub.status.busy": "2022-09-06T17:16:04.589691Z",
     "iopub.status.idle": "2022-09-06T17:16:04.591871Z",
     "shell.execute_reply": "2022-09-06T17:16:04.591614Z",
     "shell.execute_reply.started": "2022-09-06T17:16:04.589854Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sentences = [sentence.lower() for sub_sentence in sentences for sentence in sub_sentence]; sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53175eea-fc5e-479e-87bd-0f244eb24906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:16:16.744231Z",
     "iopub.status.busy": "2022-09-06T17:16:16.744093Z",
     "iopub.status.idle": "2022-09-06T17:16:16.746772Z",
     "shell.execute_reply": "2022-09-06T17:16:16.746396Z",
     "shell.execute_reply.started": "2022-09-06T17:16:16.744220Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', '4', '3 4', '2 3 4', '1 2 3 4']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences = [eosp_pattern.sub('', sentence) for sentence in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674051f5-cea0-4965-b7e9-8bacf9ec4509",
   "metadata": {
    "tags": []
   },
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4adf57da-23b3-468f-b4ea-047d6eb47f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:16:20.175705Z",
     "iopub.status.busy": "2022-09-06T17:16:20.175567Z",
     "iopub.status.idle": "2022-09-06T17:16:20.178511Z",
     "shell.execute_reply": "2022-09-06T17:16:20.178189Z",
     "shell.execute_reply.started": "2022-09-06T17:16:20.175694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', '4', '3 4', '2 3 4', '1 2 3 4']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_sentence_tokenizer(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4814b2aa-dd9e-4cf0-80a0-fe2e1d3beb13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:25:02.989644Z",
     "iopub.status.busy": "2022-09-06T17:25:02.989448Z",
     "iopub.status.idle": "2022-09-06T17:25:02.994833Z",
     "shell.execute_reply": "2022-09-06T17:25:02.994451Z",
     "shell.execute_reply.started": "2022-09-06T17:25:02.989631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 2 3 4</th>\n",
       "      <th>2 3 4</th>\n",
       "      <th>3 4</th>\n",
       "      <th>4</th>\n",
       "      <th>Mr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1 2 3 4  2 3 4  3 4  4  Mr\n",
       "0        1      1    1  1   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys\n",
    "sys.path.insert(1, '../../machine-learning')\n",
    "sys.path.insert(1, '../../homewise/ds-core/')\n",
    "#from nlp import custom_word_tokenizer, custom_sentence_tokenizer\n",
    "vec = CountVectorizer(tokenizer=custom_sentence_tokenizer, token_pattern='(?u)\\\\b\\\\w+\\\\b', lowercase = False, ngram_range=(1,1))\n",
    "tdm = vec.fit_transform([document])\n",
    "display(pd.DataFrame(tdm.toarray(), columns=vec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6fd51b3-2d4d-4a1d-9c64-5c00869a75e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:28:23.918580Z",
     "iopub.status.busy": "2022-09-06T17:28:23.918439Z",
     "iopub.status.idle": "2022-09-06T17:28:23.924749Z",
     "shell.execute_reply": "2022-09-06T17:28:23.924398Z",
     "shell.execute_reply.started": "2022-09-06T17:28:23.918568Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 2 3 4</th>\n",
       "      <th>2 3 4</th>\n",
       "      <th>2 3 4 1 2 3 4</th>\n",
       "      <th>3 4</th>\n",
       "      <th>3 4 2 3 4</th>\n",
       "      <th>3 4 2 3 4 1 2 3 4</th>\n",
       "      <th>4</th>\n",
       "      <th>4 3 4</th>\n",
       "      <th>4 3 4 2 3 4</th>\n",
       "      <th>4 3 4 2 3 4 1 2 3 4</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mr 4</th>\n",
       "      <th>Mr 4 3 4</th>\n",
       "      <th>Mr 4 3 4 2 3 4</th>\n",
       "      <th>Mr 4 3 4 2 3 4 1 2 3 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1 2 3 4  2 3 4  2 3 4 1 2 3 4  3 4  3 4 2 3 4  3 4 2 3 4 1 2 3 4  4  4 3 4  \\\n",
       "0        1      1              1    1          1                  1  1      1   \n",
       "\n",
       "   4 3 4 2 3 4  4 3 4 2 3 4 1 2 3 4  Mr  Mr 4  Mr 4 3 4  Mr 4 3 4 2 3 4  \\\n",
       "0            1                    1   1     1         1               1   \n",
       "\n",
       "   Mr 4 3 4 2 3 4 1 2 3 4  \n",
       "0                       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = CountVectorizer(tokenizer=custom_sentence_tokenizer, token_pattern='(?u)\\\\b\\\\w+\\\\b', lowercase = False, ngram_range=(1,5))\n",
    "tdm = vec.fit_transform([document])\n",
    "display(pd.DataFrame(tdm.toarray(), columns=vec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e76032c-3b87-41f6-9de4-6c7ccfcd9bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:28:50.279459Z",
     "iopub.status.busy": "2022-09-06T17:28:50.279316Z",
     "iopub.status.idle": "2022-09-06T17:28:50.284399Z",
     "shell.execute_reply": "2022-09-06T17:28:50.283945Z",
     "shell.execute_reply.started": "2022-09-06T17:28:50.279448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2 3 4\\n 1 2 3 4...</th>\n",
       "      <th>3 4.</th>\n",
       "      <th>3 4. 2 3 4\\n 1 2 3 4...</th>\n",
       "      <th>Mr. 4\\n.</th>\n",
       "      <th>Mr. 4\\n. 3 4.</th>\n",
       "      <th>Mr. 4\\n. 3 4. 2 3 4\\n 1 2 3 4...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2 3 4\\n 1 2 3 4...  3 4.  3 4. 2 3 4\\n 1 2 3 4...  Mr. 4\\n.  Mr. 4\\n. 3 4.  \\\n",
       "0                   1     1                        1         1              1   \n",
       "\n",
       "   Mr. 4\\n. 3 4. 2 3 4\\n 1 2 3 4...  \n",
       "0                                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "vec = CountVectorizer(tokenizer=sent_tokenize, token_pattern='(?u)\\\\b\\\\w+\\\\b', lowercase = False, ngram_range=(1,5))\n",
    "tdm = vec.fit_transform([document])\n",
    "display(pd.DataFrame(tdm.toarray(), columns=vec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3c269-7805-4293-8d10-6083ba191e7f",
   "metadata": {},
   "source": [
    "# custom_word_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a33a2c2-1ed3-4958-a0a7-d855189e57cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:31:27.703649Z",
     "iopub.status.busy": "2022-09-06T17:31:27.703131Z",
     "iopub.status.idle": "2022-09-06T17:31:27.705824Z",
     "shell.execute_reply": "2022-09-06T17:31:27.705515Z",
     "shell.execute_reply.started": "2022-09-06T17:31:27.703635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_word_tokenizer(document):\n",
    "    return [token for sentence in custom_sentence_tokenizer(document)\n",
    "            for token in RegexpTokenizer(CUSTOM_WORD_TOKENIZER_REGEX).tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf937819-7474-491b-b035-81d2ae825774",
   "metadata": {},
   "source": [
    "## debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97806aca-187a-428d-b6e4-d4aba0788815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:31:29.160352Z",
     "iopub.status.busy": "2022-09-06T17:31:29.160215Z",
     "iopub.status.idle": "2022-09-06T17:31:29.162988Z",
     "shell.execute_reply": "2022-09-06T17:31:29.162738Z",
     "shell.execute_reply.started": "2022-09-06T17:31:29.160341Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', '4', '3 4', '2 3 4', '1 2 3 4']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentence for sentence in custom_sentence_tokenizer(document)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b79dc91e-da37-47c1-9ac5-8b659f205ba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:32:41.852966Z",
     "iopub.status.busy": "2022-09-06T17:32:41.852824Z",
     "iopub.status.idle": "2022-09-06T17:32:41.855770Z",
     "shell.execute_reply": "2022-09-06T17:32:41.855449Z",
     "shell.execute_reply.started": "2022-09-06T17:32:41.852955Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.', '4\\n.', '3 4.', '2 3 4\\n 1 2 3 4...']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentence for sentence in PunktSentenceTokenizer().tokenize(document)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445757e-9b29-40ee-8bf7-2267f249cdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49edcfdb-a07a-42f4-9a4b-62801465a249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:31:33.008541Z",
     "iopub.status.busy": "2022-09-06T17:31:33.008400Z",
     "iopub.status.idle": "2022-09-06T17:31:33.011323Z",
     "shell.execute_reply": "2022-09-06T17:31:33.010966Z",
     "shell.execute_reply.started": "2022-09-06T17:31:33.008530Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', '4', '3', '4', '2', '3', '4', '1', '2', '3', '4']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for sentence in custom_sentence_tokenizer(document)\n",
    "            for token in RegexpTokenizer(CUSTOM_WORD_TOKENIZER_REGEX).tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa4dfb-66c9-4475-a629-1f9c9e7dba74",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ff146a6-a532-4300-9c9c-97bea12f3bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:31:42.968528Z",
     "iopub.status.busy": "2022-09-06T17:31:42.968389Z",
     "iopub.status.idle": "2022-09-06T17:31:42.971150Z",
     "shell.execute_reply": "2022-09-06T17:31:42.970869Z",
     "shell.execute_reply.started": "2022-09-06T17:31:42.968517Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', '4', '3', '4', '2', '3', '4', '1', '2', '3', '4']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_word_tokenizer(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ff7eb1bf-92a8-41e0-aac4-944e7ba93981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:31:44.054050Z",
     "iopub.status.busy": "2022-09-06T17:31:44.053788Z",
     "iopub.status.idle": "2022-09-06T17:31:44.058431Z",
     "shell.execute_reply": "2022-09-06T17:31:44.058169Z",
     "shell.execute_reply.started": "2022-09-06T17:31:44.054035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Mr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  Mr\n",
       "0  1  2  3  4   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = CountVectorizer(tokenizer=custom_word_tokenizer, lowercase = False, ngram_range=(1,1))\n",
    "tdm = vec.fit_transform([document])\n",
    "display(pd.DataFrame(tdm.toarray(), columns=vec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "954fe027-eed3-42d6-b6f3-ff919f1c12d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:30:13.079951Z",
     "iopub.status.busy": "2022-09-06T17:30:13.079810Z",
     "iopub.status.idle": "2022-09-06T17:30:13.087047Z",
     "shell.execute_reply": "2022-09-06T17:30:13.086717Z",
     "shell.execute_reply.started": "2022-09-06T17:30:13.079940Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1 2</th>\n",
       "      <th>1 2 3</th>\n",
       "      <th>1 2 3 4</th>\n",
       "      <th>2</th>\n",
       "      <th>2 3</th>\n",
       "      <th>2 3 4</th>\n",
       "      <th>2 3 4 1</th>\n",
       "      <th>2 3 4 1 2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>4 2 3 4 1</th>\n",
       "      <th>4 3</th>\n",
       "      <th>4 3 4</th>\n",
       "      <th>4 3 4 2</th>\n",
       "      <th>4 3 4 2 3</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mr 4</th>\n",
       "      <th>Mr 4 3</th>\n",
       "      <th>Mr 4 3 4</th>\n",
       "      <th>Mr 4 3 4 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  1 2  1 2 3  1 2 3 4  2  2 3  2 3 4  2 3 4 1  2 3 4 1 2  3  ...  \\\n",
       "0  1    1      1        1  2    2      2        1          1  3  ...   \n",
       "\n",
       "   4 2 3 4 1  4 3  4 3 4  4 3 4 2  4 3 4 2 3  Mr  Mr 4  Mr 4 3  Mr 4 3 4  \\\n",
       "0          1    1      1        1          1   1     1       1         1   \n",
       "\n",
       "   Mr 4 3 4 2  \n",
       "0           1  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = CountVectorizer(tokenizer=custom_word_tokenizer, lowercase = False, ngram_range=(1,5))\n",
    "tdm = vec.fit_transform([document])\n",
    "display(pd.DataFrame(tdm.toarray(), columns=vec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bbbe4f2-7560-49e3-b5ba-bbed0c64844a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T17:30:41.010179Z",
     "iopub.status.busy": "2022-09-06T17:30:41.010033Z",
     "iopub.status.idle": "2022-09-06T17:30:41.017364Z",
     "shell.execute_reply": "2022-09-06T17:30:41.017107Z",
     "shell.execute_reply.started": "2022-09-06T17:30:41.010168Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>. 2</th>\n",
       "      <th>. 2 3</th>\n",
       "      <th>. 2 3 4</th>\n",
       "      <th>. 2 3 4 1</th>\n",
       "      <th>. 3</th>\n",
       "      <th>. 3 4</th>\n",
       "      <th>. 3 4 .</th>\n",
       "      <th>. 3 4 . 2</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>4 ...</th>\n",
       "      <th>4 1</th>\n",
       "      <th>4 1 2</th>\n",
       "      <th>4 1 2 3</th>\n",
       "      <th>4 1 2 3 4</th>\n",
       "      <th>Mr.</th>\n",
       "      <th>Mr. 4</th>\n",
       "      <th>Mr. 4 .</th>\n",
       "      <th>Mr. 4 . 3</th>\n",
       "      <th>Mr. 4 . 3 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   .  . 2  . 2 3  . 2 3 4  . 2 3 4 1  . 3  . 3 4  . 3 4 .  . 3 4 . 2  ...  \\\n",
       "0  2    1      1        1          1    1      1        1          1    1   \n",
       "\n",
       "   ...  4 ...  4 1  4 1 2  4 1 2 3  4 1 2 3 4  Mr.  Mr. 4  Mr. 4 .  Mr. 4 . 3  \\\n",
       "0  ...      1    1      1        1          1    1      1        1          1   \n",
       "\n",
       "   Mr. 4 . 3 4  \n",
       "0            1  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "vec = CountVectorizer(tokenizer=word_tokenize, token_pattern='(?u)\\\\b\\\\w+\\\\b', lowercase = False, ngram_range=(1,5))\n",
    "tdm = vec.fit_transform([document])\n",
    "display(pd.DataFrame(tdm.toarray(), columns=vec.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b809f33-e30d-444c-a8bc-15ae1b30870f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
